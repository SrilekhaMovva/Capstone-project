# -*- coding: utf-8 -*-
"""final project_606

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1813P3_H51po_NSjsd_U6wpyFmd3MmUc5

Since object detection API for TensorFlow, 2.0 hasn't been updated as of the time this publication is been reviewed. So we are updating the TensorFlow on colab.
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

"""For GPU ‘Found GPU’ and tf version 1.x. Else remember to change runtime to GPU"""

import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))
print(tf.__version__)

from google.colab import drive
drive.mount('/content/gdrive')

cd /content/gdrive

ls

cd My Drive

ls

cd /content/gdrive/My Drive/images/

!git clone https://github.com/tensorflow/models.git

pwd

!apt-get install protobuf-compiler python-pil python-lxml python-tk
!pip install Cython

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/images/models/research/
!protoc object_detection/protos/*.proto --python_out=.

import os
os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/images/models/research:/content/gdrive/My Drive/images/models/research/slim'

!python setup.py build
!python setup.py install

import time, psutil
Start = time.time()- psutil.boot_time()
Left= 12*3600 - Start
print('Time remaining for this session is: ', Left/3600)

pip install tf_slim

# Commented out IPython magic to ensure Python compatibility.
#rember the last CD you did in order to specify the directory.
# %cd /content/gdrive/My Drive/images/models/research/object_detection/builders/
!python model_builder_test.py

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/images/models/research/object_detection/

pwd

cd /content/gdrive/My Drive/images

import os
import glob
import pandas as pd
import xml.etree.ElementTree as ET
def xml_to_csv(path):
    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        print(xml_file)
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            value = (root.find('filename').text,
                     int(root.find('size')[0].text),
                     int(root.find('size')[1].text),
                     member[0].text,
                     int(member[4][0].text),
                     int(member[4][1].text),
                     int(member[4][2].text),
                     int(member[4][3].text)
                     )
            xml_list.append(value)
    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']
    xml_df = pd.DataFrame(xml_list, columns=column_name)
    return xml_df
def main(directory_list):
    for Image_cat in directory_list:
        image_path = os.path.join(os.getcwd(), '{}/ann'.format(Image_cat))
        #print(image_path)
        print(image_path)
        xml_df = xml_to_csv(image_path) 
        xml_df.to_csv('{}_labels.csv'.format(Image_cat), index=None)
        print('{}_labels.csv'.format(Image_cat))
        print('Successfully converted xml to csv.')
main(['train_50','test_50'])



# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/images/models/research/object_detection/

# Commented out IPython magic to ensure Python compatibility.
# %ls

!python generate_tfrecord.py --label='invoice_no' --csv_input="/content/gdrive/My Drive/images/train_50_labels.csv" --output_path=train.record --img_path="/content/gdrive/My Drive/images/train_50/imgs/"

!python generate_tfrecord.py --label='invoice_no' --csv_input="/content/gdrive/My Drive/images/test_50_labels.csv" --output_path=test.record --img_path="/content/gdrive/My Drive/images/test_50/imgs"

# Commented out IPython magic to ensure Python compatibility.
# %pwd

!wget https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config

!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz
!tar -xvf ssd_mobilenet_v1_coco_11_06_2017.tar.gz

import time, psutil
Start = time.time()- psutil.boot_time()
Left= 12*3600 - Start
print('Time remaining for this session is: ', Left/3600)

pip install tensorboardcolab

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir invoice_training/



cd /content/gdrive/My Drive/images/models/research/object_detection/

ls

!python train.py --logtostderr --train_dir=invoice_training/ --pipeline_config_path=ssd_mobilenet.config

!python export_inference_graph.py --input_type image_tensor --pipeline_config_path ssd_mobilenet.config --trained_checkpoint_prefix invoice_training/model.ckpt-57286 --output_directory trained_inference_graph/

!zip -r Arduino_exp_graph.zip trained_inference_graph

import numpy as np
import os
import six.moves.urllib as urllib
import sys
import tarfile
import tensorflow as tf
import zipfile
from distutils.version import StrictVersion
from collections import defaultdict
from io import StringIO
from matplotlib import pyplot as plt
from PIL import Image

sys.path.append("..")
from object_detection.utils import ops as utils_ops
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util

MODEL_NAME = 'trained_inference_graph'
PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'
PATH_TO_LABELS = 'invoice_data/invoice_lables.pbtxt'
NUM_CLASSES = 1

detection_graph = tf.Graph()
with detection_graph.as_default():
  od_graph_def = tf.GraphDef()
  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:
    serialized_graph = fid.read()
    od_graph_def.ParseFromString(serialized_graph)
    tf.import_graph_def(od_graph_def, name='')

category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)

def load_image_into_numpy_array(image):
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

PATH_TO_TEST_IMAGES_DIR = '/content/gdrive/My Drive/images/train_50/imgs/'
#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 600) ]
IMAGE_SIZE = (12, 8)
TEST_IMAGE_PATHS=[]
for root,dirs,files in os.walk(PATH_TO_TEST_IMAGES_DIR):
  for file in files:
    if file.endswith(".jpg"):
      TEST_IMAGE_PATHS.append(os.path.join(PATH_TO_TEST_IMAGES_DIR, file))

print(TEST_IMAGE_PATHS)

def run_inference_for_single_image(image, graph):
  with graph.as_default():
    with tf.Session() as sess:
      # Get handles to input and output tensors
      ops = tf.get_default_graph().get_operations()
      all_tensor_names = {output.name for op in ops for output in op.outputs}
      tensor_dict = {}
      for key in [
          'num_detections', 'detection_boxes', 'detection_scores',
          'detection_classes', 'detection_masks'
      ]:
        tensor_name = key + ':0'
        if tensor_name in all_tensor_names:
          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(
              tensor_name)
      if 'detection_masks' in tensor_dict:
        # The following processing is only for single image
        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])
        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])
        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.
        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)
        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])
        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])
        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
            detection_masks, detection_boxes, image.shape[1], image.shape[2])
        detection_masks_reframed = tf.cast(
            tf.greater(detection_masks_reframed, 0.5), tf.uint8)
        # Follow the convention by adding back the batch dimension
        tensor_dict['detection_masks'] = tf.expand_dims(
            detection_masks_reframed, 0)
      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')

      # Run inference
      output_dict = sess.run(tensor_dict,
                             feed_dict={image_tensor: image})

      # all outputs are float32 numpy arrays, so convert types as appropriate
      output_dict['num_detections'] = int(output_dict['num_detections'][0])
      output_dict['detection_classes'] = output_dict[
          'detection_classes'][0].astype(np.int64)
      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]
      output_dict['detection_scores'] = output_dict['detection_scores'][0]
      if 'detection_masks' in output_dict:
        output_dict['detection_masks'] = output_dict['detection_masks'][0]
  return output_dict

cd /content/gdrive/My Drive/images/test_50/imgs/

image_path = '/content/gdrive/My Drive/images/test_50/imgs/'

pwd

i=0
for image_path in TEST_IMAGE_PATHS:
  image = Image.open(image_path)
  # the array based representation of the image will be used later in order to prepare the
  # result image with boxes and labels on it.
  image_np = load_image_into_numpy_array(image)
  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
  image_np_expanded = np.expand_dims(image_np, axis=0)
  # Actual detection.
  output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)
  # Visualization of the results of a detection.
  vis_util.visualize_boxes_and_labels_on_image_array(
      image_np,
      output_dict['detection_boxes'],
      output_dict['detection_classes'],
      output_dict['detection_scores'],
      category_index,
      instance_masks=output_dict.get('detection_masks'),
      use_normalized_coordinates=True,
      line_thickness=1)
  display(Image.fromarray(image_np))
  Image.fromarray(image_np).save(str(i)+".jpg")





